{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "I want to create a sample data set of 100 grid cells (10km x 10km)\n",
    "near Fairbanks. I will use actual data where I can easily find it\n",
    "and otherise I will generate random data. This sample dataset will \n",
    "demonstrate the correct \"shape\" (variables and their dimensions) for \n",
    "the ** new** input files to dvm-dos-tem.\n",
    "\n",
    "## Summary of Requirements\n",
    "\n",
    "* Data should be in a rectangular (grid) layout.\n",
    "* NetCDF.\n",
    "* Attempting to conform to CF & COARDS standards.\n",
    "* Geospatial information must be with the file. Each file should\n",
    "have variables for Lat and Lon each defined interms of the\n",
    "dimensions of (y, x), where (y, x) are the rectangular grid \n",
    "coordinates.\n",
    "\n",
    "> Is computing GIRR the only place that latitude is needed?\n",
    "\n",
    "> Maybe it is possible to precompute GIRR?\n",
    "\n",
    "> Is longitude even used?  \n",
    "\n",
    "# Process\n",
    "\n",
    "## Driving climate file (nirr, vapo, tair, prec)\n",
    "\n",
    "\n",
    "First step is to pick some y,x or lat/lon bounding box coordinates \n",
    "to use with `gdal_translate` for subsetting the AIEM domain \n",
    "data files from SNAP. The files I have from SNAP are in Alaska Albers\n",
    "projection, 1km pixel size.\n",
    "\n",
    "With Google Maps, I take a guess at where the Bonanza Creek LTER is from\n",
    "the sattelite view (64.667557, -148.489804), and then eyeball the location \n",
    "~5km north and west of there (64.708950, -148.633313) so that my new \n",
    "subwindow is more or less centered on the LTER site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with a netcdf file as opposed to the tif, I can use `ncview` to \n",
    "quickly check coordinates and data values to make sure the commands are \n",
    "doing what I expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the \"creation option\" means that special \n",
    "# variables will be written to the new netcdf file mapping\n",
    "# row/column coordinates to lat/lon\n",
    "!gdal_translate -of netCDF -co \"WRITE_LONLAT=YES\" \\\n",
    "../../snap-data/tas_mean_C_iem_cccma_cgcm3_1_sresa1b_2001_2100/tas_mean_C_iem_cccma_cgcm3_1_sresa1b_01_2001.tif \\\n",
    "temporary_with_lonlat.nc\n",
    "\n",
    "# see what we got\n",
    "#!ncdump -h temporary_with_lonlat.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `gdal_translate` would let me specify the coordinates for my\n",
    "subwindow in lon/lat, (projection coordinates), for some reason I want\n",
    "a nice, square, 10x10km data set, so I use the row/column coordinates\n",
    "that I find using `ncview`: (64.708950, -148.633313) which is roughly\n",
    "(j=1134, i=991) as far as `ncview` is concerned. `gdal_translate` wants\n",
    "the \"source window\" defined in terms of (xoff, yoff, xsize, ysize).\n",
    "\n",
    "If I was not concerned with the exact pixel size of the sample dataset\n",
    "I could instead speficy the \"source window\" to `gdal_translate` using\n",
    "\"projection coordinates\", assuming the source file has the right geo-\n",
    "spatial information with it.\n",
    "\n",
    "Anyways, use `gdal_translate` again to grab the sub-window, specifying \n",
    "the coordinates with pixel and line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Actually I seem to be having problems with the y axis\n",
    "# ordering again. So while I pick pixel(i,j): (915,1548), when I \n",
    "# use those numbers for xoff and yoff, the resulting image is not\n",
    "# in the right place. If I 'reverse' the y (j) coordinate, \n",
    "# so 1850 - (1548 - 10) = 292, then the image comes out correct\n",
    "# with (0,0) being the lower left corner, and the pixel we selected\n",
    "# as Toolik, or close to it.\n",
    "#\n",
    "# NOTE: this means I need to fix the Bonanza Creek coords!!!\n",
    "\n",
    "# -srcwin 915 292 10 10  #  Toolik ~(68.538, -149.6275)\n",
    "# -srcwin 991 1134 10 10  #  Bonanza Creek area\n",
    "!gdal_translate -of netCDF -co \"WRITE_LONLAT=YES\" -co GDAL_NETCDF_BOTTOMUP=YES \\\n",
    "-srcwin 915 292 10 10 temporary_with_lonlat.nc temp_subset_with_lonlat.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out what we got\n",
    "#!ncdump -h temp_subset_with_lonlat.nc\n",
    "!gdalinfo temp_subset_with_lonlat.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: I am going to hardcode the (0,0) pixel to have the exact same,\n",
    "values as the input data for Toolik for testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fire_dataset(fname, sizey=10, sizex=10):\n",
    "    ncfile = netCDF4.Dataset(fname, mode='w', format='NETCDF4')\n",
    "\n",
    "    Y = ncfile.createDimension('Y', sizey)\n",
    "    X = ncfile.createDimension('X', sizex)\n",
    "\n",
    "    fri = ncfile.createVariable('fri', np.int, ('Y','X',))\n",
    "    fri[:] = np.random.uniform(low=1, high=7, size=(10, 10))\n",
    "    fri[0,0] = 1000\n",
    "    \n",
    "    fire_year_vector = ncfile.createVLType(np.int, 'fire_year_vector')\n",
    "    fire_years = ncfile.createVariable('fire_years', fire_year_vector, ('Y','X'))\n",
    "\n",
    "    fire_sizes = ncfile.createVariable('fire_sizes', fire_year_vector, ('Y','X'))\n",
    "\n",
    "    yr_data = np.empty(sizey * sizex, object)\n",
    "    sz_data = np.empty(sizey * sizex, object)\n",
    "    for n in range(sizey * sizex):\n",
    "        yr_data[n] = np.array(sorted(np.random.randint(1900, 2006, np.random.randint(0,10,1))), dtype=np.int)\n",
    "        sz_data[n] = np.random.randint(0,100,len(yr_data[n]))\n",
    "        #numpy.arange(random.randint(1,10),dtype='int32')+1\n",
    "    \n",
    "    yr_data = np.reshape(yr_data,(sizey,sizex))\n",
    "    sz_data = np.reshape(sz_data,(sizey,sizex))\n",
    "\n",
    "    print(yr_data[0,0], \"-->\", sz_data[0,0]) \n",
    "    print(yr_data[0,1], \"-->\", sz_data[0,1])\n",
    "    print(yr_data[9,9], \"-->\", sz_data[9,9])\n",
    "    \n",
    "    fire_years[:] = yr_data\n",
    "    fire_sizes[:] = sz_data\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ncfile.close()   \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Create the new fire file...\n",
    "make_fire_dataset(\"new-fire-dataset.nc\", sizey=10, sizex=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncdump -h new-fire-dataset.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_veg_classification(fname, sizey=10, sizex=10):\n",
    "    ncfile = netCDF4.Dataset(fname, mode='w', format='NETCDF4')\n",
    "\n",
    "    Y = ncfile.createDimension('Y', sizey)\n",
    "    X = ncfile.createDimension('X', sizex)\n",
    "\n",
    "    veg_class = ncfile.createVariable('veg_class', np.int, ('Y', 'X',))\n",
    "    veg_class[:] = np.random.uniform(low=1, high=7, size=(10,10))\n",
    "    veg_class[0,0] = 4\n",
    "    \n",
    "    ncfile.close()\n",
    "\n",
    "# Create a new veg_classification file\n",
    "make_veg_classification(\"new-veg-dataset.nc\", sizey=10, sizex=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_drainage_classification(fname, sizey=10, sizex=10):\n",
    "    ncfile = netCDF4.Dataset(fname, mode='w', format='NETCDF4')\n",
    "\n",
    "    Y = ncfile.createDimension('Y', sizey)\n",
    "    X = ncfile.createDimension('X', sizex)\n",
    "\n",
    "    drainage_class = ncfile.createVariable('drainage_class', np.int, ('Y', 'X',))\n",
    "    drainage_class[:] = np.random.uniform(low=1, high=7, size=(10,10))\n",
    "    drainage_class[0,0] = 0\n",
    "    ncfile.close()\n",
    "\n",
    "# Create a new veg_classification file\n",
    "make_drainage_classification(\"new-drainage-dataset.nc\", sizey=10, sizex=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_run_mask(filename, sizey=10, sizex=10):\n",
    "    ncfile = netCDF4.Dataset(filename, mode='w', format='NETCDF4')\n",
    "    Y = ncfile.createDimension('Y', sizey)\n",
    "    X = ncfile.createDimension('X', sizex)\n",
    "\n",
    "    run = ncfile.createVariable('run', np.int, ('Y', 'X',))\n",
    "    run[:] = np.zeros((10,10))\n",
    "    run[0,0] = 1\n",
    "    \n",
    "    ncfile.close()\n",
    "\n",
    "# Create a new run mask file (all ones for now)\n",
    "make_run_mask('run-mask.nc', sizey=10, sizex=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_co2_to_new_style(filename):\n",
    "    '''Creates an co2 file for dvmdostem from the old sample data'''\n",
    "    old_ncfile = netCDF4.Dataset(\"../DATA/test_single_site/dataregion/co2.nc\", mode='r')\n",
    "    new_ncfile = netCDF4.Dataset(filename, mode='w', format='NETCDF4')\n",
    "\n",
    "    # Dimensions\n",
    "    yearD = new_ncfile.createDimension('year', None) # append along time axis\n",
    "    \n",
    "    # Coordinate Variable\n",
    "    yearV = new_ncfile.createVariable('year', np.int, ('year',))\n",
    "    \n",
    "    # Data Variables\n",
    "    co2 = new_ncfile.createVariable('co2', np.float32, ('year',))\n",
    "    \n",
    "    yearV[:] = old_ncfile.variables['YEAR'][:]\n",
    "    co2[:] = old_ncfile.variables['CO2'][:]\n",
    "    \n",
    "    old_ncfile.close()\n",
    "    new_ncfile.close()\n",
    "    \n",
    "# Copy over the co2 file\n",
    "copy_co2_to_new_style('new-co2-dataset.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_climate_nc_file(filename, sizey=10, sizex=10):\n",
    "    '''Creates an empty climate file for dvmdostem; y,x grid, time unlimited.'''\n",
    "    \n",
    "    ncfile = netCDF4.Dataset(filename, mode=\"w\", format='NETCDF4')\n",
    "    \n",
    "    # Dimensions for the file.\n",
    "    time_dim = ncfile.createDimension('time', None) # append along time axis\n",
    "    Y = ncfile.createDimension('Y', sizey)\n",
    "    X = ncfile.createDimension('X', sizex)\n",
    "\n",
    "    # Coordinate Variables\n",
    "    Y = ncfile.createVariable('Y', np.int, ('Y',))\n",
    "    X = ncfile.createVariable('X', np.int, ('X',))\n",
    "    Y[:] = np.arange(0, sizey)\n",
    "    X[:] = np.arange(0, sizex)\n",
    "    \n",
    "    # 'Spatial Refefence' variables (?)\n",
    "    lat = ncfile.createVariable('lat', np.float32, ('Y', 'X',))\n",
    "    lon = ncfile.createVariable('lon', np.float32, ('Y', 'X',))\n",
    "    \n",
    "    # Create data variables\n",
    "    #co2 = ncfile.createVariable('co2', np.float32, ('time')) # actually year\n",
    "    temp_air = ncfile.createVariable('tair', np.float32, ('time', 'Y', 'X',))\n",
    "    precip = ncfile.createVariable('precip', np.float32, ('time', 'Y', 'X',))\n",
    "    nirr = ncfile.createVariable('nirr', np.float32, ('time', 'Y', 'X',))\n",
    "    vapor_press = ncfile.createVariable('vapor_press', np.float32, ('time', 'Y', 'X',))\n",
    "    \n",
    "    ncfile.close()\n",
    "    \n",
    "# Make a new file to copy data into\n",
    "create_empty_climate_nc_file('new-climate-dataset.nc', sizey=10, sizex=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the 'temporary' dataset\n",
    "temp_subset_with_lonlat = netCDF4.Dataset('temp_subset_with_lonlat.nc', mode='r')\n",
    "\n",
    "# Open the new file for appending\n",
    "new_climatedataset = netCDF4.Dataset('new-climate-dataset.nc', mode='a')\n",
    "\n",
    "# Grab the lat and lon from the temporary file\n",
    "lat = new_climatedataset.variables['lat']\n",
    "lon = new_climatedataset.variables['lon']\n",
    "lat[:] = temp_subset_with_lonlat.variables['lat'][:]\n",
    "lon[:] = temp_subset_with_lonlat.variables['lon'][:]\n",
    "\n",
    "#tair = new_climatedateset.variables['tair']\n",
    "#tair[0,:,:] = temp_subset_with_lonlat.variables['Band1'][:]\n",
    "\n",
    "new_climatedataset.close()\n",
    "temp_subset_with_lonlat.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ncdump -h temp_subset_with_lonlat.nc\n",
    "#!ncdump temp_subset_with_lonlat.nc\n",
    "#!ncdump new-climate-dataset.nc\n",
    "\n",
    "#Check the values at 0,0 to see that everythting looks correct:\n",
    "!ncks -v lat,lon -d Y,0,0,1 -d X,0,0,1 new-climate-dataset.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a basic dataset with the lat/lon coordinates. Time to populate it with bit of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with netCDF4.Dataset('new-climate-dataset.nc', mode='a') as new_climatedataset:\n",
    "\n",
    "    YEARS = 10\n",
    "\n",
    "    TIMESTEPS=YEARS*12\n",
    "\n",
    "    # # Write random, junk data to the climate file\n",
    "    # new_climatedataset = netCDF4.Dataset('new-climate-dataset.nc', mode='a')\n",
    "\n",
    "    sx = new_climatedataset.variables['X'].size\n",
    "    sy = new_climatedataset.variables['Y'].size\n",
    "\n",
    "    junkA = np.random.uniform(low=0.0, high=10, size=(TIMESTEPS*sy*sx)).reshape(TIMESTEPS, sy, sx)\n",
    "    junkB = np.random.uniform(low=0.0, high=1300, size=(TIMESTEPS*sy*sx)).reshape(TIMESTEPS, sy, sx)\n",
    "    junkC = np.random.uniform(low=0.0, high=20, size=(TIMESTEPS*sy*sx)).reshape(TIMESTEPS, sy, sx)\n",
    "\n",
    "    new_climatedataset.variables['precip'][:] = junkA\n",
    "    new_climatedataset.variables['nirr'][:] = junkB\n",
    "    new_climatedataset.variables['vapor_press'][:] = junkC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ncks -v nirr new-climate-dataset.nc\n",
    "!ncdump -h new-climate-dataset.nc\n",
    "print YEARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the new file for appending\n",
    "with netCDF4.Dataset('new-climate-dataset.nc', mode='a') as new_climatedataset:\n",
    "\n",
    "    for yridx, year in enumerate(range(2010, 2010+YEARS)):\n",
    "        for midx, month in enumerate(range (1,13)): # Note 1 based month!\n",
    "            print year, month\n",
    "            # TRANSLATE TO NETCDF\n",
    "            # The curly braces are needed to run the shell command from w/in\n",
    "            # ipython and have the variable exansion with year and month\n",
    "            # work out alright\n",
    "            print \"Converting tif --> netcdf...\"\n",
    "            !gdal_translate -of netCDF \\\n",
    "            {\"../../snap-data/tas_mean_C_iem_cccma_cgcm3_1_sresa1b_2001_2100/tas_mean_C_iem_cccma_cgcm3_1_sresa1b_%02d_%04d.tif\" % (month, year)} \\\n",
    "            temporary_tair.nc\n",
    "            !gdal_translate -of netCDF \\\n",
    "            {\"../../snap-data/rsds_mean_MJ-m2-d1_iem_cccma_cgcm3_1_sresa1b_2001_2100/rsds_mean_MJ-m2-d1_iem_cccma_cgcm3_1_sresa1b_%02d_%04d.tif\" % (month, year)} \\\n",
    "            temporary_rsds.nc\n",
    "            !gdal_translate -of netCDF \\\n",
    "            {\"../../snap-data/pr_total_mm_iem_cccma_cgcm3_1_sresa1b_2001_2100/pr_total_mm_iem_cccma_cgcm3_1_sresa1b_%02d_%04d.tif\" % (month, year)} \\\n",
    "            temporary_pr.nc\n",
    "            !gdal_translate -of netCDF \\\n",
    "            {\"../../snap-data/vap_mean_hPa_iem_cccma_cgcm3_1_sresa1b_2001_2100/vap_mean_hPa_iem_cccma_cgcm3_1_sresa1b_%02d_%04d.tif\" % (month, year)} \\\n",
    "            temporary_vapo.nc\n",
    "\n",
    "            print \"Subsetting....\"\n",
    "            !gdal_translate -of netCDF \\\n",
    "            -srcwin 915 292 10 10 temporary_tair.nc temporary_tair2.nc\n",
    "            !gdal_translate -of netCDF \\\n",
    "            -srcwin 915 292 10 10 temporary_rsds.nc temporary_rsds2.nc\n",
    "            !gdal_translate -of netCDF \\\n",
    "            -srcwin 915 292 10 10 temporary_pr.nc temporary_pr2.nc\n",
    "            !gdal_translate -of netCDF \\\n",
    "            -srcwin 915 292 10 10 temporary_vapo.nc temporary_vapo2.nc\n",
    "\n",
    "            print \"Writing subset's data to new files...\"\n",
    "            with netCDF4.Dataset('temporary_tair2.nc', mode='r') as t2:\n",
    "                # Grab the lat and lon from the temporary file\n",
    "                tair = new_climatedataset.variables['tair']\n",
    "                tair[yridx*12+midx] = t2.variables['Band1'][:]\n",
    "\n",
    "            with netCDF4.Dataset('temporary_rsds2.nc', mode='r') as t2:\n",
    "                # Grab the lat and lon from the temporary file\n",
    "                nirr = new_climatedataset.variables['nirr']\n",
    "                nirr[yridx*12+midx] = t2.variables['Band1'][:]\n",
    "                \n",
    "            with netCDF4.Dataset('temporary_pr2.nc', mode='r') as t2:\n",
    "                # Grab the lat and lon from the temporary file\n",
    "                prec = new_climatedataset.variables['precip']\n",
    "                prec[yridx*12+midx] = t2.variables['Band1'][:]\n",
    "\n",
    "            with netCDF4.Dataset('temporary_vapo2.nc', mode='r') as t2:\n",
    "                # Grab the lat and lon from the temporary file\n",
    "                vapo = new_climatedataset.variables['vapor_press']\n",
    "                vapo[yridx*12+midx] = t2.variables['Band1'][:]\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "print \"Done appending. Closing the new file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncdump -h new-climate-dataset.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = 0\n",
    "X = 0\n",
    "with netCDF4.Dataset('new-climate-dataset.nc', mode='a') as new_climatedataset:\n",
    "    plt.plot(new_climatedataset.variables['tair'][:,Y,X])\n",
    "    plt.plot(new_climatedataset.variables['precip'][:,Y,X])\n",
    "    plt.plot(new_climatedataset.variables['nirr'][:,Y,X])\n",
    "    plt.plot(new_climatedataset.variables['vapor_press'][:,Y,X], label='vapor_press')\n",
    "    \n",
    "\n",
    "with netCDF4.Dataset('../DATA/Toolik_Inputs/datacht/cccma_a1b.nc', mode='a') as old_climatedataset:\n",
    "    CLMID = 0\n",
    "    plt.plot(old_climatedataset.variables['TAIR'][CLMID,0:10,:].flatten(), label='TAIR')  \n",
    "    plt.plot(old_climatedataset.variables['PREC'][CLMID,0:10,:].flatten(), label='PREC')  \n",
    "    plt.plot(old_climatedataset.variables['NIRR'][CLMID,0:10,:].flatten()/10, label='NIRR') \n",
    "    plt.plot(old_climatedataset.variables['VAPO'][CLMID,0:10,:].flatten(), label='VAPO') \n",
    "    \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with netCDF4.Dataset('../DATA/Toolik_Inputs/datacht/cccma_a1b.nc', mode='a') as old_climatedataset:\n",
    "    \n",
    "    CLMID = 0\n",
    "    plt.plot(old_climatedataset.variables['TAIR'][CLMID,0:10,:].flatten(), label='TAIR')  \n",
    "    plt.plot(old_climatedataset.variables['PREC'][CLMID,0:10,:].flatten(), label='PREC')  \n",
    "    plt.plot(old_climatedataset.variables['NIRR'][CLMID,0:10,:].flatten()/8, label='NIRR')  \n",
    "    #plt.legend()\n",
    "#     plt.plot(old_climatedataset.variables['precip'][:,Y,X])\n",
    "#     plt.plot(old_climatedataset.variables['nirr'][:,Y,X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ncdump -h ../DATA/Toolik_Inputs/datacht/cccma_a1b.nc\n",
    "!ncks -v CLMID ../DATA/Toolik_Inputs/datacht/cccma_a1b.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncdump ../DATA/Toolik_Inputs/datacht/cohortid.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncdump -h ../DATA/Toolik_Inputs/datacht/climate.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def randrange(n, vmin, vmax):\n",
    "    return (vmax-vmin)*np.random.rand(n) + vmin\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "n = 100\n",
    "for c, m, zl, zh in [('r', 'o', -50, -25), ('b', '^', -30, -5)]:\n",
    "    xs = randrange(n, 23, 32)\n",
    "    ys = randrange(n, 0, 100)\n",
    "    zs = randrange(n, zl, zh)\n",
    "    ax.scatter(xs, ys, zs, c=c, marker=m)\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temporary.nc\") as f:\n",
    "    print(\"Hmmm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
