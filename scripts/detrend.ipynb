{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "* [De-trending climate data](#De-trending-climate-data)\n",
    "  * [Setup](#Setup)\n",
    "    * [Software](#Software)\n",
    "    * [Data](#Data)\n",
    "  * [Initial Exploration](#Initial-Exploration)\n",
    "  * [Try with real data](#Try-with-real-data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De-trending climate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some projects, we need to use the projected climate scenarios \n",
    "without the warming (or cooling) trend that is present in each \n",
    "month (or season).\n",
    "\n",
    "For instance in a situation where, over 100 years, January\n",
    "becomes warmer, but July becomes cooler, we would like to remove \n",
    "the warming trend from January and the cooling trend from July.\n",
    "\n",
    "We'd like to remove any trend that might be present for a given month\n",
    "over the next 100 years, for every pixel in the AIEM domain. \n",
    "\n",
    "A single climate driver variable for dvmdostem, over the whole \n",
    "AIEM domain for 100 years at 1km spatial resolution and 1 monthly \n",
    "time resolution takes ~21GB per variable:\n",
    "\n",
    "    1850*2560 = 4,736,000 pixels in AIEM domain, including oceans, etc.\n",
    "\n",
    "    4 bytes\n",
    "    ----------- * 12 months * 200 years * (1850*2560) = 22,732,800,000 bytes\n",
    "    32bit float\n",
    "\n",
    "    22,732,800,000 / 1024 / 1024 / 1024 = 21.17 GB\n",
    "\n",
    "\n",
    "We need to do this for 4 variables (air temp, vapor pressure, \n",
    "near infrared radiation, and precipitation) for six scenarios (echam, \n",
    "hadley? ccma? etc?). Thus we need to process ~500GB of data.\n",
    "\n",
    "In this notebook we will outline the process for removing\n",
    "a trend from the timeseries climate data downloaded from \n",
    "SNAP in a (hopefully) computationally reasonable amount of time: (??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will call some external shell commands, so you must \n",
    "have the appropriate software installed and available on the path \n",
    "that IPython uses. For the most part things should work if you \n",
    "install your software with the system package manager (e.g. apt-get \n",
    "or yum or homebrew)\n",
    "\n",
    "* GDAL command line utilities (specifically `gdalbuildvrt`)\n",
    "\n",
    "Also you will need the following python libraries.\n",
    "\n",
    "* `netCDF4`\n",
    "* `matplotlib`\n",
    "* `scipy.signal`\n",
    "* `rasterio`\n",
    "* `IPython Notebook` (for running or adding to this .ipynb file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook assumeses that you have downloaded the climate\n",
    "files from SNAP and have extracted all the `.tifs` so that you have a \n",
    "directory strucutre something like this (assuming you are working with \n",
    "temperature). Note that the data is organized with a `.tif` image for each\n",
    "month for the next 100 years (1200 files):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ├── tas_mean_C_iem_cccma_cgcm3_1_sresa1b_2001_2100\n",
    "    │   ├── tas_mean_C_iem_cccma_cgcm3_1_sresa1b_01_2001.tif\n",
    "    │   ├── tas_mean_C_iem_cccma_cgcm3_1_sresa1b_01_2002.tif\n",
    "    |   ........\n",
    "    │   ├── tas_mean_C_iem_cccma_cgcm3_1_sresa1b_12_2099.tif\n",
    "    │   └── tas_mean_C_iem_cccma_cgcm3_1_sresa1b_12_2100.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we are working in a directory \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many techniques for de-trending data. Ideally we can\n",
    "use `scipy.signal.detrend` from SciPy's signal processing library\n",
    "and avoid having to devise our own custom detrending algorithm. \n",
    "\n",
    "So first we need to play around with `scipy.signal.detrend` until \n",
    "we are convinced it will work for our needs.\n",
    "\n",
    "Start by loading some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "\n",
    "# IPython \"magic\" to allow plots to be displayed inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create an x range and a few basic signals over that range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 1000\n",
    "x = np.arange(0, SIZE)\n",
    "\n",
    "noise = np.random.uniform(low=-50, high=50, size=SIZE)\n",
    "sin_wave = 100 * np.sin( (np.pi/180) * x )\n",
    "trend = np.linspace(-500, 500, SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout what we have created so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, noise, label='noise')\n",
    "plt.plot(x, sin_wave, label='sin wave')\n",
    "plt.plot(x, trend, label = 'trend')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add our basic components together to create a \n",
    "noisy, trending, sin wave. This should be somewhat similar\n",
    "to how one of our climate variables might look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_sin = noise + sin_wave\n",
    "noisy_trending_sin = noisy_sin + trend\n",
    "\n",
    "plt.plot(x, noisy_sin, label='noisy sin wave')\n",
    "plt.plot(x, noisy_trending_sin, label='noisy, trending, sin wave')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking pretty good. Now to see what exactly the \n",
    "`scipy.signal.detrend` function does. There are two \n",
    "options for how you'd like the detrending to happen, \n",
    "'linear' and 'constant'. Accodring to the [documentation](http://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.detrend.html#scipy.signal.detrend),\n",
    "the linear subtracts the result of a least-squares fit for the\n",
    "the signal from the signal. The constant option subtracts \n",
    "the mean of the signal from the original signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_detrend = scipy.signal.detrend(noisy_trending_sin, type='linear')\n",
    "con_detrend = scipy.signal.detrend(noisy_trending_sin, type='constant')\n",
    "\n",
    "plt.plot(x, noisy_trending_sin, label='noisy trending sin')\n",
    "plt.plot(x, lin_detrend, label='linear detrend')\n",
    "plt.plot(x, scipy.signal.detrend(noisy_trending_sin, type='constant'), label='constant detrend')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, interesting. Looks like the linear option is what we want\n",
    "for our application.\n",
    "\n",
    "However, it looks like the linear detrending seems to center the \n",
    "resulting signal around zero, so we will need to offset the \n",
    "result to line up with the initial reading in the initial signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_lin_detrend = lin_detrend + (noisy_trending_sin[0] - lin_detrend[0])\n",
    "plt.plot(x, noisy_trending_sin, label='noisy trending sin')\n",
    "plt.plot(x, offset_lin_detrend,  label='offset linear detrend')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that is looking pretty darn good. If we end up needing a \n",
    "more complicated line fitting algorithm (e.g. cubic spline) for \n",
    "finding the trend maybe we can riff on the `scipy.signal.detrend`.\n",
    "\n",
    "For now this seems like it should work. Lets try it on some of \n",
    "our actual data. But first, lets cleanup and release the memory\n",
    "needed for this test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load up some libraries for working with the `.tif`\n",
    "files from SNAP. After the reset magic from above, we have to grab\n",
    "numpy, matplotlib and scipy.signal again too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "\n",
    "import rasterio\n",
    "import netCDF4  # Not using this yet, but may want to write netcdf file??\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use GDAL's notion of \"Virtual Raster Tiles\" \n",
    "to assemble a \"view\"of our 1200 files that shows only one \n",
    "month, but for the entire  set of years. We are essentially\n",
    "creating a new file by combining all the files that would be\n",
    "listed with this command: \n",
    "\n",
    "    $ ls tas_mean_C_iem_cccma_cgcm3_1_sresa1b_01_*.tif\n",
    "    \n",
    "So, 100 files; 100 years worth of January.\n",
    "    \n",
    "GDAL Utilities has a tool, `gdalbuildvrt`, that can quickly \n",
    "create such a \"view file\", or \"Virtual Raster Tile\" file that \n",
    "behaves just like a `.tif` would. This is essentially an \"index\"\n",
    "into a set of `.tif` input files, and allows us to access the data\n",
    "in the \"shape\" we want without having to create a copy of the data.\n",
    "The \"Virtual Raster Tile\" file has extension `.vrt`. Beacause a \n",
    "`.vrt` file behaves identically to a `.tif`, we can open and \n",
    "handle the `.vrt` files with the same programs or tools we \n",
    "might use on a `tif` file, but the `.vrt` file can be composed \n",
    "from a subset of one or more bands in one or more input files. \n",
    "\n",
    "In our case we want to be able to open the `.vrt` file and read it \n",
    "into a `numpy` datastructure so that we can use `signal.scipy.detrend` \n",
    "on the data; we will likely want to write this detrended numpy \n",
    "datastructure out to a new file as well.\n",
    "\n",
    "We will use the exclamation mark to access the system shell commands\n",
    "for `ls` and `gdalbuildvrt`. We will also use the IPyhton magic to \"time\"\n",
    "the execution, and \"reset\" to free up some memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the files we'd like to include \n",
    "# in our virtual dataset. For starters, we'll \n",
    "# just pick January for all years:\n",
    "!ls ../../snap-data/tas_mean_C_iem_cccma_cgcm3_1_sresa1b_2001_2100/tas_mean_C_iem_cccma_cgcm3_1_sresa1b_01* > janfiles.txt\n",
    "\n",
    "# Next, we ask gdalbuildvrt to create a .vrt file\n",
    "# from all the files in the list we just created.\n",
    "#   -seperate      each file to a stacked band\n",
    "#   -b 1           use band number 1 from each input file\n",
    "%time !gdalbuildvrt -separate -b 1 -input_file_list janfiles.txt jan.vrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad for creating an index into ~20GBs of (sorted) data.\n",
    "\n",
    "> NOTE: Not sure what the malloc error in `gdalbuildvrt` \n",
    "> is all about. Seems to come up after the operation is \"done\"\n",
    "> though, so it seems like our file should be ok. Maybe we should\n",
    "> report a bug.\n",
    "\n",
    "Now we can open and read the `.vrt` file just as we would \n",
    "a `.tif` file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! NOTE !! uses ~15 seconds, ~1.7GB of RAM!\n",
    "with rasterio.open('jan.vrt') as src: \n",
    "    temperature_data = src.read(masked=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was not able to get Rasterio's masking to work, so I read the \n",
    "data in and then we will work on masking out the invalid pixels.\n",
    "\n",
    "This is for one month, so to do all months, we are looking at \n",
    "`(~15secs * 12months)/(60secs/min) ~= 3min`, so about three minutes of \n",
    "file-reading time for one variable, one scenario. \n",
    "~3 min x 4 variables x 6 scenarios comes out to ~72 minutes \n",
    "of file-reading time for all our data. Not trivial, but totally\n",
    "reasonable for nearly 500GBs of data...\n",
    "\n",
    "If we look at the data we can see that it looks to be the correct shape.\n",
    "The axes (dimensions) appear to be (time, y, x). So we have a \"stack\" of \n",
    "images, with each item in the stack being an image along the time axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mask_report(data):\n",
    "  '''Print some info about a masked array'''\n",
    "  shape = data.shape\n",
    "  sz = data.size\n",
    "  mv = np.count_nonzero(data.mask)\n",
    "  print(type(mv), type(sz))\n",
    "  print(mv, sz)\n",
    "  pcnt = 100.0* mv/sz\n",
    "  print(\"Shape: %s Total size: %s Masked values: %s. Percent Masked: %0.7f\" % (str(shape), sz, mv, pcnt))\n",
    "\n",
    "s = np.random.uniform(0,100,1000)\n",
    "s = np.ma.masked_outside(s, 10, 90)\n",
    "print_mask_report(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions are (time, y, x) \n",
    "# from upper left corner of image\n",
    "# (not sure which corner of the pixel)\n",
    "\n",
    "print(\"Type of data: \", type(temperature_data))\n",
    "print(\"Size of data: \", temperature_data.nbytes/1024/1024, \"(Mbs)\")\n",
    "print(\"Shape of data: \", temperature_data.shape)\n",
    "print(\"Min value: \", np.min(temperature_data))\n",
    "print(\"Max value: \", np.max(temperature_data))\n",
    "print(\"------------------\")\n",
    "print(\"Using mask?:\", temperature_data.mask)\n",
    "print(\"Fill value:\", temperature_data.fill_value)\n",
    "print(\"First value (should be masked):\", temperature_data[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure why, but it seems that even though our data is a \n",
    "masked array and the fill value seems correct, the mask doesn't\n",
    "seem to be used because the upper left corner pixel, which should\n",
    "be masked out, shows up. If it were masked, printing the value\n",
    "should result in '--', or some other indication that the data\n",
    "is hidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(temperature_data.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't ensure that the oceans and other no-data areas are \n",
    "recoginized and appropriately excluded from calculations and displays, \n",
    "then the automatic scaleing can make plots difficult to interpert. Usually\n",
    "the scale ends up far too large in order to accomodate the very-large or\n",
    "very-small values used for no-data pixels.\n",
    "\n",
    "There might be a faster way to do this, but this seems to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data = np.ma.masked_outside(temperature_data[:,:,:], -500, 500, copy=False) \n",
    "np.count_nonzero(temperature_data.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(temperature_data[0])\n",
    "plt.title(\"temperature, timestep0\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going thru the entire detrending and conversion process \n",
    "one time, I discovered that there are a few \"bad\" pixels that have \n",
    "data missing somehere along the time axis but are not necessarily\n",
    "\"bad\" at all timesteps. These values can results in `RunTime` warnings \n",
    "or errors, which I think these are coming from trying to perform math \n",
    "on the very large or very small values used for missing data.\n",
    "\n",
    "If there were no \"bad\" pixels, then we'd expect the number of masked\n",
    "pixels to be constant through time (we haven't implemented any \"coastal\n",
    "erosion\" features yet!). Instead, it looks like we have a varying number of\n",
    "masked pixels through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_masked = [np.count_nonzero(img.mask) for img in (temperature_data)]\n",
    "\n",
    "mincnt = np.min(count_masked)\n",
    "maxcnt = np.max(count_masked)\n",
    "diff = mincnt-maxcnt\n",
    "\n",
    "print(\"# of masked values min, max: %i, %i. (delta: %i)\" % (mincnt, maxcnt, maxcnt-mincnt))\n",
    "\n",
    "p = plt.plot(count_masked[:], label=\"# of masked pixels\")\n",
    "plt.xlabel(\"timestep\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we'd like is one mask that excludes every pixel that has\n",
    "an undefined value anywhere along its time dimension. Fortunately\n",
    "`numpy.ma` provides an \"any\" function that does just that.\n",
    "\n",
    "To see examples where the pixels are defined in the first timeslice, \n",
    "but somewhere along the time axis are undefined, we invert the mask\n",
    "for the first timeslice and combine it with the \"any\" mask. Remember,\n",
    "a `True` value in the mask means \"yes this item _is_ to be hidden\".\n",
    "\n",
    "There are not very many of these 'bad' pixels, which makes them very\n",
    "difficult to actually notice when looking at a map with a normal\n",
    "colorbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives us a 2D array with all \"bad\" pixels masked.\n",
    "aggressive_mask = temperature_data.mask.any(0)\n",
    "\n",
    "# pixels that are good at timestep zero, but masked due to\n",
    "# a bad value somewhere along the time axis\n",
    "plt.imshow( np.logical_and(aggressive_mask, np.invert(temperature_data[0].mask)), cmap='gray', interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look more closely at this area to make sure we\n",
    "know what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T0 = 0\n",
    "T1 = 95\n",
    "\n",
    "fig, ((ax1,ax2,ax3),(ax4,ax5,ax6)) = plt.subplots(2,3)\n",
    "\n",
    "# large zoom, bristol bay\n",
    "yl=1200; yh=1700; xl=400; xh=900; extents=[xl,xh,yh,yl]\n",
    "ax1.imshow( temperature_data[T0,yl:yh,xl:xh], interpolation='none', extent=extents )\n",
    "ax1.set_title(\"large zoom t=%s\"%T0)\n",
    "\n",
    "# med zoom, bristol bay\n",
    "yl=1250; yh=1400; xl=550; xh=700; extents=[xl,xh,yh,yl] \n",
    "ax2.imshow( temperature_data[T0,yl:yh,xl:xh], interpolation='none', extent=extents )\n",
    "ax2.set_title(\"med zoom t=%s\"%T0)\n",
    "\n",
    "# Tiny zoom bristol bay\n",
    "yl=1300; yh=1310; xl=640; xh=650; extents=[xl,xh, yh, yl]\n",
    "ax3.imshow( temperature_data[T0,yl:yh,xl:xh], interpolation='none', extent=extents )\n",
    "ax3.set_title(\"tight zoom t=%s\"%T0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# large zoom, bristol bay\n",
    "yl=1200; yh=1700; xl=400; xh=900; extents=[xl,xh,yh,yl]\n",
    "ax4.imshow( temperature_data[T1,yl:yh,xl:xh], interpolation='none', extent=extents )\n",
    "ax4.set_title(\"large zoom t=%s\"%T1)\n",
    "\n",
    "# med zoom, bristol bay\n",
    "yl=1250; yh=1400; xl=550; xh=700; extents=[xl,xh,yh,yl] \n",
    "ax5.imshow( temperature_data[T1,yl:yh,xl:xh], interpolation='none', extent=extents )\n",
    "ax5.set_title(\"med zoom t=%s\"%T1)\n",
    "\n",
    "# Tiny zoom bristol bay\n",
    "yl=1300; yh=1310; xl=640; xh=650; extents=[xl,xh, yh, yl]\n",
    "ax6.imshow( temperature_data[T1,yl:yh,xl:xh], interpolation='none', extent=extents )\n",
    "ax6.set_title(\"tight zoom t=%s\"%T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(temperature_data[:,1301,642])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scipy.signal.detrend(temperature_data[:,1301,642]) )\n",
    "plt.plot(scipy.signal.detrend(temperature_data[:,1305,642]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now what we want to do is take the \"any\" mask, (most\n",
    "aggressive, hides all pixels that don't have complete time-\n",
    "series), and apply that to each image in our series.\n",
    "                                            , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAYBE DON'T EVEN NEED THIS?\n",
    "# since detrend seems to ignore the mask anyways...\n",
    "# Apply the most aggressive mask to every timeslice.\n",
    "# for i, img in enumerate(temperature_data[:]):\n",
    "#     temperature_data.mask[i,:,:] = temperature_data.mask.any(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrd = scipy.signal.detrend(temperature_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS PRODUCES OVERFLOW...\n",
    "#np.float32(3.4028235e+38) + np.float32(3.4028235e+38)\n",
    "\n",
    "dtrd = np.ma.masked_outside(dtrd, -100, 100)\n",
    "\n",
    "count_masked_d = [np.count_nonzero(img.mask) for img in dtrd]\n",
    "\n",
    "mincnt_d = np.min(count_masked_d)\n",
    "maxcnt_d = np.max(count_masked_d)\n",
    "diff_d = mincnt_d - maxcnt_d\n",
    "\n",
    "print(\"ORIG # of masked values min, max: %i, %i. (delta: %i)\" % (mincnt, maxcnt, maxcnt - mincnt))\n",
    "print(\"DTRD # of masked values min, max: %i, %i. (delta: %i)\" % (mincnt_d, maxcnt_d, maxcnt_d - mincnt_d))\n",
    "p = plt.plot(count_masked[:], label=\"# of masked px odata\")\n",
    "p = plt.plot(count_masked_d[:], label=\"# of masked px dtrddata\")\n",
    "plt.xlabel(\"timestep\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dtrd[0,500:1500,0:1500])\n",
    "#plt.imshow(np.ma.masked_outside(dtrd[2,:,:], -100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write each timestep to a nc file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dtrd[:,1301,642])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrd_ofs = dtrd + (temperature_data[0,:,:] - dtrd[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dtrd_ofs[0,1250:1350,550:650], interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0, 1000).reshape((10,10,10))\n",
    "a[0,3:7,3:7] = -99999\n",
    "a = np.ma.masked_outside(a, -6000,6000)\n",
    "#plt.imshow(a[0], interpolation='none')\n",
    "b = a + 100\n",
    "# plt.imshow(b[0], interpolation='none')\n",
    "# plt.colorbar()\n",
    "\n",
    "# plt.imshow( (a[0]**2+a[0:4])[0] )\n",
    "# plt.colorbar()\n",
    "# a = np.ma.masked_inside(a, 30, 70)\n",
    "# plt.plot(a)\n",
    "# b = a + np.arange(0,100)\n",
    "# plt.plot(b)\n",
    "\n",
    "\n",
    "sdt = scipy.signal.detrend(a, axis=0)\n",
    "plt.plot(sdt[:,1,1])\n",
    "plt.plot(a[:,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we can look at the timeseries for a \n",
    "# pixel in central alaska that should have data\n",
    "plt.plot(temperature_data[:, 550, 1050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the `scipy.signal.detrend` function over\n",
    "the time axis for every pixel on the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another 15 seconds or so and a lot of memory. There might\n",
    "# be a better way to do this.\n",
    "temperature_data.mask[0] = temperature_data.mask.any(0)\n",
    "temperature_data.mask.shape\n",
    "\n",
    "%time dtrd = scipy.signal.detrend(temperature_data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then look at the detrended timeseries for\n",
    "a pixel. The `scipy.signal.detrend` centers the resulting\n",
    "signal around zero. We can offset the signal back to its \n",
    "original position by adding the first value of the original\n",
    "timeseries to the detrended vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = 550\n",
    "X = 1050\n",
    "plt.suptitle(\"Pixel(y,x): (%s, %s)\" % (Y, X))\n",
    "plt.plot(temperature_data[:,Y,X], label='original')\n",
    "plt.plot(dtrd[:,Y,X], label='detrended')\n",
    "plt.plot((dtrd[:,Y,X] + (temperature_data[0,Y,X] - dtrd[0,Y,X])), label='dtrend+offset')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out it is blazingly fast to add the offset\n",
    "to the array in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dtrd[:,:,:] += (temperature_data[0,:,:] - dtrd[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the timeseries for each pixel in the image\n",
    "has been detrended and offset so that the detrended\n",
    "timeseries begins at the same value as the original \n",
    "timeseries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrd = np.ma.masked_outside(dtrd[:,:,:], -500, 500, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temperature_data.min(), temperature_data.max())\n",
    "print(dtrd.min(), dtrd.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pixel(orig, detrended, Y = 550, X = 1050):\n",
    "    plt.suptitle(\"Pixel(y,x): (%s, %s)\" % (Y, X))\n",
    "    plt.plot(orig[:,Y,X], label='original')\n",
    "    plt.plot(detrended[:,Y,X], label='detrended')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_pixel(temperature_data, dtrd, Y=550,X=1050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_pixel(temperature_data, dtrd, Y=1200, X=780)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the method worked out we will write a\n",
    "more generalized script that can be used on all four variables\n",
    "and likely will concatenate the months to create new output series\n",
    "in the same shape/format as the original input tifs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yikes, lots of memory use! \n",
    "# See what we are using:\n",
    "print(dtrd.nbytes/1024.0/1024.0/1024.0, \"GBs\")\n",
    "print(temperature_data.nbytes/1024.0/1024.0/1024.0, \"GBs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_pixel(temperature_data, dtrd, Y=992, X=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temperature_data[0,500,500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(temperature_data[0,:,:].mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(temperature_data[0,:,:].mask - temperature_data[:,:,:].mask.any(0))\n",
    "plt.imshow(np.logical_or(temperature_data[:,:,:].mask.any(0), temperature_data[0,:,:].mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larget area, has some issues...\n",
    "# T=7\n",
    "# yl = 1245\n",
    "# yh = 1755\n",
    "# xl = 287\n",
    "# xh = 797\n",
    "# extents=[xl,xh, yh, yl]\n",
    "\n",
    "# med tight zoom, bristol bay\n",
    "# T=7\n",
    "# yl = 1250\n",
    "# yh = 1455\n",
    "# xl = 550\n",
    "# xh = 700\n",
    "# extents=[xl,xh, yh, yl]\n",
    "\n",
    "# Tiny zoom bristol bay\n",
    "T=90\n",
    "yl = 1300\n",
    "yh = 1310\n",
    "xl = 640\n",
    "xh = 650\n",
    "extents=[xl,xh, yh, yl]\n",
    "\n",
    "\n",
    "# SUPER TIGHT ZOOM IN ON \n",
    "# island sw of Kodiak. Has some issues, first timestep...\n",
    "# T=0\n",
    "# yl = 1645\n",
    "# yh = 1655\n",
    "# xl = 687\n",
    "# xh = 697\n",
    "# extents=[xl,xh, yh, yl]\n",
    "\n",
    "otemps = temperature_data[T,yl:yh,xl:xh]\n",
    "dtemps = dtrd[T,yl:yh,xl:xh]\n",
    "mdtemps = np.ma.masked_outside(dtemps, -100, 100)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "ax1.imshow(otemps, extent=extents, interpolation='none')\n",
    "ax1.set_title(\"original temps t=%s\"%T)\n",
    "\n",
    "ax2.imshow( mdtemps, interpolation='none', extent=extents)\n",
    "ax2.set_title(\"detrended temps t=%s\"%T)\n",
    "\n",
    "\n",
    "print(np.min(otemps), np.max(otemps), (np.min(otemps) < 0 and (np.min(otemps) > -1))) # and \n",
    "print(np.min(dtemps), np.max(dtemps))\n",
    "print(np.min(mdtemps), np.max(mdtemps))\n",
    "\n",
    "# print \"Original Temps:\", otemps\n",
    "# print \"Detrended Temps:\", dtemps\n",
    "# print \"Maseked, Detrended Temps:\", mdtemps\n",
    "\n",
    "\n",
    "\n",
    "#plt.colorbar(temperature_data[T,yl:yh,xl:xh])\n",
    "# extent=[80,120,32,0]\n",
    "\n",
    "#ax1.imshow(temperature_data[0:1250,1750:250,750])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_pixel(temperature_data, dtrd, X=642, Y=1301)\n",
    "plt.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.179043990183396e-37 <0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temperature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((5,3,3))\n",
    "a[4,2,1] = np.inf\n",
    "am = np.ma.masked_outside(a, -100, 100)\n",
    "print(am.mask)\n",
    "am.mask.any(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anything masked along the zero-th dimension, but not masked in the first timeslice, so \"false\".\n",
    "plt.imshow( np.logical_and(temperature_data.mask.any(0), np.invert(temperature_data[0].mask)), cmap='gray')\n",
    "plt.title(\"These pixels are missing data somewhere along the time axis!!, but are defined in the first timeslice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(0,99, 100).reshape((10,10))\n",
    "b = np.ma.masked_outside(a, 30, 80).mask\n",
    "c = np.ma.masked_inside(a, 50, 60).mask\n",
    "d = np.logical_or(b,c)\n",
    "e = np.logical_and(c, ~b)\n",
    "# print a\n",
    "# print b\n",
    "# print c\n",
    "# print d\n",
    "# print e\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\n",
    "\n",
    "ax1.imshow(a, interpolation='none', cmap='jet')\n",
    "ax1.set_title(\"a\")\n",
    "\n",
    "ax2.imshow( b, interpolation='none', cmap='gray', alpha=1.0)\n",
    "\n",
    "ax2.set_title(\"b\")\n",
    "\n",
    "ax3.imshow( c, interpolation='none', cmap='gray', alpha=1.0)\n",
    "ax3.set_title(\"c\")\n",
    "\n",
    "ax4.imshow( d, interpolation='none', cmap='gray', alpha=1.0)\n",
    "ax4.set_title(\"d=(c||b)\")\n",
    "\n",
    "ax5.imshow( np.invert(e), interpolation='none', cmap='gray', alpha=1.0)\n",
    "ax5.set_title(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1,1] = 3000\n",
    "a_mask = np.ma.masked_outside(a, -100, 100).mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
